#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–çš„å®Œæ•´ç‰ˆç¿»è¯‘å™¨æ‰“åŒ…è„šæœ¬
é€šè¿‡ç²¾ç¡®æ§åˆ¶torchæ¨¡å—æ¥å‡å°‘æ–‡ä»¶å¤§å°
"""

import os
import sys
import shutil
import subprocess
from pathlib import Path

def create_optimized_spec():
    """åˆ›å»ºä¼˜åŒ–çš„PyInstaller specæ–‡ä»¶"""
    spec_content = '''
# -*- mode: python ; coding: utf-8 -*-

# è‡ªå®šä¹‰hookæ¥ç²¾ç¡®æ§åˆ¶torchæ¨¡å—
from PyInstaller.utils.hooks import collect_submodules, collect_data_files

# åªåŒ…å«whisperå’ŒåŸºç¡€torchåŠŸèƒ½éœ€è¦çš„æ¨¡å—
torch_modules = [
    'torch',
    'torch.nn',
    'torch.nn.functional', 
    'torch.nn.modules',
    'torch.nn.modules.activation',
    'torch.nn.modules.batchnorm',
    'torch.nn.modules.conv',
    'torch.nn.modules.linear',
    'torch.nn.modules.normalization',
    'torch.nn.modules.transformer',
    'torch.nn.modules.utils',
    'torch.nn.parameter',
    'torch.nn.init',
    'torch.optim',
    'torch.utils',
    'torch.utils.data',
    'torch.cuda',
    'torch.jit',
    'torch.autograd',
    'torch.tensor',
    'torch._C',
    'torch.serialization',
    'torch.storage',
    'torch.multiprocessing',
    'torch.hub',
    'torch.backends',
    'torch.backends.cudnn',
    'torch.backends.cuda',
    'torch.fx',
    'torch.overrides',
    'torch.types',
    'torch.testing',
    'torch._utils',
    'torch.library',
    'torch.masked',
    'torch.sparse',
    'torch.special',
    'torch.linalg',
    'torch.fft',
    'torch.random',
]

# whisperç›¸å…³æ¨¡å—
whisper_modules = [
    'whisper',
    'whisper.model',
    'whisper.audio',
    'whisper.decoding',
    'whisper.tokenizer',
    'whisper.normalizers',
    'whisper.timing',
    'whisper.utils',
]

a = Analysis(
    ['gui_main.py'],
    pathex=[],
    binaries=[],
    datas=[
        # åŒ…å«whisperçš„èµ„äº§æ–‡ä»¶ - ä½¿ç”¨åŠ¨æ€è·¯å¾„
    ] + collect_data_files('whisper'),
    hiddenimports=torch_modules + whisper_modules + [
        'soundcard',
        'numpy',
        'numpy._core',
        'numpy._core.multiarray',
        'numpy._core.overrides',
        'numpy.__config__',
        'tkinter',
        'tkinter.ttk',
        'tkinter.scrolledtext',
        'threading',
        'queue',
        'translators',
        'translators.server',
        'translators.apis',
        'argostranslate',
        'argostranslate.package',
        'argostranslate.translate',
        'ctranslate2',
        'sentencepiece',
        'stanza',
        'regex',
        'tqdm',
        'requests',
        'urllib3',
        'certifi',
        'charset_normalizer',
        'idna',
        'more_itertools',
        'tiktoken',
        'tiktoken_ext',
        'tiktoken_ext.openai_public',
    ],
    hookspath=[],
    hooksconfig={
        'numpy': {
            'include_version_info': False,
            'exclude_tests': True
        }
    },
    runtime_hooks=[],
    excludes=[
        # æ’é™¤torchä¸­ä¸éœ€è¦çš„å¤§å‹æ¨¡å—
        'torch.distributed',
        'torch.distributed.algorithms',
        'torch.distributed.elastic',
        'torch.distributed.fsdp',
        'torch.distributed.optim',
        'torch.distributed.pipeline',
        'torch.distributed.rpc',
        'torch.distributed.tensor',
        'torch.distributed._shard',
        'torch.distributed._tools',
        'torch.ao',  # é‡åŒ–ç›¸å…³
        'torch.ao.quantization',
        'torch.ao.pruning',
        'torch.ao.sparsity',
        'torch.quantization',
        'torch.jit._script',
        'torch.jit._trace',
        'torch.jit.mobile',
        'torch.mobile',
        'torch.package',
        'torch.profiler',
        'torch.utils.benchmark',
        'torch.utils.bottleneck',
        'torch.utils.collect_env',
        'torch.utils.cpp_extension',
        'torch.utils.deterministic',
        'torch.utils.dlpack',
        'torch.utils.hipify',
        'torch.utils.mobile_optimizer',
        'torch.utils.model_zoo',
        'torch.utils.tensorboard',
        'torch.utils.viz',
        'torch.onnx',
        'torch.xpu',
        'torch.mps',
        'torch.mtia',
        
        # æ’é™¤torchvisionå’Œtorchaudioï¼ˆå¦‚æœä¸éœ€è¦ï¼‰
        'torchvision',
        'torchaudio',
        
        # æ’é™¤å…¶ä»–å¤§å‹åº“
        'tensorflow',
        'keras',
        'sklearn',
        'scipy.optimize',
        'scipy.sparse',
        'scipy.spatial',
        'scipy.stats',
        'scipy.signal',
        'scipy.integrate',
        'scipy.interpolate',
        'scipy.io',
        'scipy.linalg',
        'scipy.ndimage',
        'scipy.special',
        'matplotlib',
        'plotly',
        'seaborn',
        'bokeh',
        'PIL.ImageQt',
        'PIL.ImageTk',
        'cv2',
        'skimage',
        
        # æ’é™¤å¼€å‘å’Œæµ‹è¯•å·¥å…·
        'pytest',
        'unittest',
        'doctest',
        'pdb',
        'bdb',
        'trace',
        'cProfile',
        'profile',
        'pstats',
        'timeit',
        
        # æ’é™¤æ–‡æ¡£å·¥å…·
        'sphinx',
        'docutils',
        'jinja2',
        'babel',
        'pygments',
        
        # æ’é™¤jupyterç›¸å…³
        'jupyter',
        'IPython',
        'notebook',
        'ipykernel',
        'ipywidgets',
        
        # æ’é™¤ç½‘ç»œæœåŠ¡å™¨
        'tornado',
        'flask',
        'django',
        'fastapi',
        'uvicorn',
        'gunicorn',
        
        # æ’é™¤æ•°æ®åº“ï¼ˆä¿ç•™sqlite3ï¼Œå®ƒæ˜¯Pythonæ ‡å‡†åº“ï¼‰
        'pymongo',
        'psycopg2',
        'mysql',
        
        # æ’é™¤å…¶ä»–ä¸éœ€è¦çš„æ¨¡å—ï¼ˆä¿ç•™æ ¸å¿ƒæ ‡å‡†åº“æ¨¡å—ï¼‰
        'curses',
        'readline',
        'rlcompleter',
    ],
    noarchive=False,
    optimize=2,
)

# è¿›ä¸€æ­¥è¿‡æ»¤ï¼Œç§»é™¤ä¸éœ€è¦çš„torchå­æ¨¡å—
a.pure = [x for x in a.pure if not any([
    # è¿‡æ»¤torchä¸­çš„å¤§å‹å­æ¨¡å—
    x[0].startswith('torch.distributed'),
    x[0].startswith('torch.ao'),
    x[0].startswith('torch.quantization'),
    x[0].startswith('torch.mobile'),
    x[0].startswith('torch.package'),
    x[0].startswith('torch.profiler'),
    x[0].startswith('torch.onnx'),
    x[0].startswith('torch.xpu'),
    x[0].startswith('torch.mps'),
    x[0].startswith('torch.mtia'),
    x[0].startswith('torch.utils.benchmark'),
    x[0].startswith('torch.utils.bottleneck'),
    x[0].startswith('torch.utils.cpp_extension'),
    x[0].startswith('torch.utils.tensorboard'),
    x[0].startswith('torch.utils.viz'),
    x[0].startswith('torch.utils.mobile_optimizer'),
    x[0].startswith('torch.utils.model_zoo'),
    x[0].startswith('torch.jit._script'),
    x[0].startswith('torch.jit._trace'),
    x[0].startswith('torch.jit.mobile'),
    
    # è¿‡æ»¤æµ‹è¯•æ¨¡å—
    x[0].startswith('test'),
    x[0].endswith('_test'),
    x[0].endswith('.test'),
    'test' in x[0].lower() and not x[0].startswith('torch.testing'),
    
    # è¿‡æ»¤æ–‡æ¡£å’Œè°ƒè¯•æ¨¡å—
    x[0].startswith('pydoc'),
    x[0].startswith('doctest'),
    x[0].startswith('pdb'),
    x[0].startswith('bdb'),
    x[0].startswith('trace'),
    
    # è¿‡æ»¤ä¸éœ€è¦çš„numpyå­æ¨¡å—
    x[0].startswith('numpy.distutils'),
    x[0].startswith('numpy.f2py'),
    x[0].startswith('numpy.testing') and x[0] != 'numpy.testing',
    x[0].startswith('numpy.doc'),
    
    # è¿‡æ»¤scipyå¤§å‹å­æ¨¡å—
    x[0].startswith('scipy.optimize'),
    x[0].startswith('scipy.sparse'),
    x[0].startswith('scipy.spatial'),
    x[0].startswith('scipy.stats'),
    x[0].startswith('scipy.signal'),
    x[0].startswith('scipy.integrate'),
    x[0].startswith('scipy.interpolate'),
    x[0].startswith('scipy.io'),
    x[0].startswith('scipy.linalg'),
    x[0].startswith('scipy.ndimage'),
    x[0].startswith('scipy.special'),
])]

# è¿‡æ»¤äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œç§»é™¤ä¸éœ€è¦çš„DLL
a.binaries = [x for x in a.binaries if not any([
    # è¿‡æ»¤å¤§å‹CUDAåº“ï¼ˆå¦‚æœä¸ä½¿ç”¨GPUï¼‰
    'cublas' in x[0].lower(),
    'cudnn' in x[0].lower(),
    'cufft' in x[0].lower(),
    'curand' in x[0].lower(),
    'cusolver' in x[0].lower(),
    'cusparse' in x[0].lower(),
    'nvrtc' in x[0].lower(),
    'nvcuda' in x[0].lower(),
    
    # è¿‡æ»¤ä¸éœ€è¦çš„åº“
    'mkl_' in x[0].lower() and 'mkl_core' not in x[0].lower() and 'mkl_intel_thread' not in x[0].lower(),
    'libiomp5md' in x[0].lower(),
    'tbb' in x[0].lower(),
])]

pyz = PYZ(a.pure)

exe = EXE(
    pyz,
    a.scripts,
    a.binaries,
    a.datas,
    [],
    name='OptimizedTranslator',
    debug=False,
    bootloader_ignore_signals=False,
    strip=True,
    upx=True,
    upx_exclude=[],
    runtime_tmpdir=None,
    console=False,
    disable_windowed_traceback=False,
    argv_emulation=False,
    target_arch=None,
    codesign_identity=None,
    entitlements_file=None,
    icon=None,
)
'''
    
    with open('optimized_full.spec', 'w', encoding='utf-8') as f:
        f.write(spec_content)
    print("âœ“ åˆ›å»ºä¼˜åŒ–specæ–‡ä»¶")

def install_dependencies():
    """å®‰è£…å¿…è¦çš„ä¾èµ–"""
    dependencies = [
        'torch>=2.0.0',
        'torchaudio>=2.0.0', 
        'openai-whisper',
        'soundcard',
        'numpy',
        'translators',
        'argostranslate',
        'tiktoken'
    ]
    
    for dep in dependencies:
        try:
            __import__(dep.split('>=')[0].split('==')[0].replace('-', '_'))
            print(f"âœ“ {dep} å·²å®‰è£…")
        except ImportError:
            print(f"æ­£åœ¨å®‰è£… {dep}...")
            subprocess.run([sys.executable, '-m', 'pip', 'install', dep], check=True)

def build_executable():
    """æ„å»ºå¯æ‰§è¡Œæ–‡ä»¶"""
    try:
        cmd = [sys.executable, '-m', 'PyInstaller', '--clean', 'optimized_full.spec']
        result = subprocess.run(cmd, check=True, capture_output=True, text=True)
        print("âœ“ æ„å»ºä¼˜åŒ–ç‰ˆå¯æ‰§è¡Œæ–‡ä»¶æˆåŠŸ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ æ„å»ºå¤±è´¥: {e}")
        print(f"é”™è¯¯è¾“å‡º: {e.stderr}")
        return False

def create_package():
    """åˆ›å»ºä¾¿æºåŒ…"""
    dist_dir = Path('dist')
    release_dir = Path('release_optimized')
    
    if release_dir.exists():
        shutil.rmtree(release_dir)
    release_dir.mkdir()
    
    # å¤åˆ¶å¯æ‰§è¡Œæ–‡ä»¶
    exe_file = dist_dir / 'OptimizedTranslator.exe'
    if exe_file.exists():
        shutil.copy2(exe_file, release_dir)
        size_mb = exe_file.stat().st_size / (1024 * 1024)
        print(f"âœ“ ä¼˜åŒ–ç‰ˆå¯æ‰§è¡Œæ–‡ä»¶å¤§å°: {size_mb:.1f} MB")
    
    # åˆ›å»ºä½¿ç”¨è¯´æ˜
    readme_content = """ä¼˜åŒ–ç‰ˆå®æ—¶ç¿»è¯‘å™¨ä½¿ç”¨è¯´æ˜

è¿™æ˜¯ä¸€ä¸ªç»è¿‡ä¼˜åŒ–çš„å®Œæ•´åŠŸèƒ½å®æ—¶ç¿»è¯‘å·¥å…·ï¼Œåœ¨ä¿æŒæ‰€æœ‰åŠŸèƒ½çš„åŒæ—¶æ˜¾è‘—å‡å°‘äº†æ–‡ä»¶å¤§å°ã€‚

åŠŸèƒ½ç‰¹æ€§:
âœ… å®æ—¶è¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘
âœ… æ”¯æŒä¸­è‹±æ–‡åŒå‘ç¿»è¯‘
âœ… GPU/CPUè‡ªåŠ¨é€‚é…
âœ… å¤šç§ç¿»è¯‘è´¨é‡æ¨¡å¼
âœ… éŸ³é¢‘è®¾å¤‡è‡ªåŠ¨æ£€æµ‹
âœ… ä¼˜åŒ–çš„æ–‡ä»¶å¤§å°

ä½¿ç”¨æ–¹æ³•:
1. åŒå‡» OptimizedTranslator.exe å¯åŠ¨ç¨‹åº
2. ç­‰å¾…æ¨¡å‹åŠ è½½å®Œæˆ
3. é€‰æ‹©éŸ³é¢‘è¾“å…¥è®¾å¤‡ï¼ˆå»ºè®®ä½¿ç”¨"é»˜è®¤æ‰¬å£°å™¨"è¿›è¡Œç³»ç»ŸéŸ³é¢‘æ•è·ï¼‰
4. é€‰æ‹©ç¿»è¯‘æ–¹å‘ï¼ˆè‹±è¯‘ä¸­æˆ–ä¸­è¯‘è‹±ï¼‰
5. ç‚¹å‡»"å¼€å§‹ç¿»è¯‘"æŒ‰é’®
6. ç¨‹åºå°†å®æ—¶æ•è·éŸ³é¢‘å¹¶æ˜¾ç¤ºç¿»è¯‘ç»“æœ

ä¼˜åŒ–è¯´æ˜:
- ç§»é™¤äº†torchä¸­ä¸å¿…è¦çš„åˆ†å¸ƒå¼è®¡ç®—ã€é‡åŒ–ã€ç§»åŠ¨ç«¯ç­‰æ¨¡å—
- æ’é™¤äº†å¤§å‹ç§‘å­¦è®¡ç®—åº“ï¼ˆscipyã€matplotlibç­‰ï¼‰
- ä¿ç•™äº†whisperå’Œç¿»è¯‘åŠŸèƒ½çš„æ ¸å¿ƒä¾èµ–
- åº”ç”¨äº†ä»£ç ä¼˜åŒ–å’Œå‹ç¼©æŠ€æœ¯

æ³¨æ„äº‹é¡¹:
- é¦–æ¬¡ä½¿ç”¨æ—¶éœ€è¦ä¸‹è½½Whisperæ¨¡å‹ï¼Œè¯·ä¿æŒç½‘ç»œè¿æ¥
- å»ºè®®åœ¨å®‰é™ç¯å¢ƒä¸­ä½¿ç”¨ä»¥è·å¾—æ›´å¥½çš„è¯†åˆ«æ•ˆæœ
- å¦‚æœé‡åˆ°GPUå…¼å®¹æ€§é—®é¢˜ï¼Œç¨‹åºä¼šè‡ªåŠ¨åˆ‡æ¢åˆ°CPUæ¨¡å¼

ç‰ˆæœ¬: ä¼˜åŒ–å®Œæ•´ç‰ˆ
"""
    
    with open(release_dir / 'ä½¿ç”¨è¯´æ˜.txt', 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    print(f"âœ“ åˆ›å»ºä¼˜åŒ–ç‰ˆä¾¿æºåŒ…: {release_dir}")
    return True

def main():
    print("å¼€å§‹æ„å»ºä¼˜åŒ–ç‰ˆå®Œæ•´ç¿»è¯‘å™¨...")
    
    # æ£€æŸ¥å’Œå®‰è£…ä¾èµ–
    print("æ£€æŸ¥ä¾èµ–...")
    install_dependencies()
    
    # åˆ›å»ºä¼˜åŒ–çš„specæ–‡ä»¶
    create_optimized_spec()
    
    # æ„å»ºå¯æ‰§è¡Œæ–‡ä»¶
    if build_executable():
        # åˆ›å»ºä¾¿æºåŒ…
        create_package()
        print("\nğŸ‰ ä¼˜åŒ–ç‰ˆå®Œæ•´ç¿»è¯‘å™¨æ„å»ºå®Œæˆ!")
        print("å¯æ‰§è¡Œæ–‡ä»¶ä½äº: release_optimized/OptimizedTranslator.exe")
        print("\nä¼˜åŒ–æ•ˆæœ:")
        print("- ä¿ç•™äº†æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½ï¼ˆè¯­éŸ³è¯†åˆ«+ç¿»è¯‘ï¼‰")
        print("- æ˜¾è‘—å‡å°‘äº†æ–‡ä»¶å¤§å°")
        print("- ç§»é™¤äº†ä¸å¿…è¦çš„torchæ¨¡å—")
        print("- ä¼˜åŒ–äº†ä¾èµ–åº“ç»“æ„")
    else:
        print("âŒ ä¼˜åŒ–ç‰ˆå®Œæ•´ç¿»è¯‘å™¨æ„å»ºå¤±è´¥")

if __name__ == '__main__':
    main()